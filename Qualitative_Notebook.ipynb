{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing with slideflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import slideflow as sf\n",
    "\n",
    "# Create the WSI object with the slide and Grayson's ROI CSV\n",
    "#wsi_grayson represents instance of sfs WSI class, which is whole slide image along with the ROI annotations. \n",
    "# printing object tells you each ROI, it's coordinates, and label. Can also access class methods to get thumbnails etc. \n",
    "wsi_grayson = sf.WSI(\n",
    "    path=\"/home/joeychan/labshare/SLIDES/PDCD10/TAM_then_4NQO/AF102F.svs\",\n",
    "    tile_px=256,\n",
    "    tile_um=128,\n",
    "    rois=\"/home/joeychan/labshare/PROJECTS/PDCD10/rois/grayson/AF102F.csv\"\n",
    ")\n",
    "\n",
    "wsi_anna = sf.WSI(\n",
    "    path=\"/home/joeychan/labshare/SLIDES/PDCD10/TAM_then_4NQO/AF102F.svs\",\n",
    "    tile_px=256,\n",
    "    tile_um=128,\n",
    "    rois=\"/home/joeychan/labshare/PROJECTS/PDCD10/rois/anna/AF102F.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wsi_grayson.rois)\n",
    "roi0 = wsi_grayson.rois[0]\n",
    "print(\"ROI label:\", roi0.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import slideflow as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon as MplPolygon\n",
    "\n",
    "# Create wsi objects that represent the slides, ROIs, and labels\n",
    "wsi_grayson = sf.WSI(\n",
    "    path=\"/home/joeychan/labshare/SLIDES/PDCD10/TAM_then_4NQO/AF102F.svs\",\n",
    "    tile_px=256,\n",
    "    tile_um=128,\n",
    "    rois=\"/home/joeychan/labshare/PROJECTS/PDCD10/rois/grayson/AF102F.csv\"\n",
    ")\n",
    "\n",
    "wsi_anna = sf.WSI(\n",
    "    path=\"/home/joeychan/labshare/SLIDES/PDCD10/TAM_then_4NQO/AF102F.svs\",\n",
    "    tile_px=256,\n",
    "    tile_um=128,\n",
    "    rois=\"/home/joeychan/labshare/PROJECTS/PDCD10/rois/anna/AF102F.csv\"\n",
    ")\n",
    "\n",
    "# Generate thumbnails without ROI overlays\n",
    "thumb_grayson = wsi_grayson.thumb(width=1024, rois=False)\n",
    "thumb_anna = wsi_anna.thumb(width=1024, rois=False)\n",
    "\n",
    "# Calculate scaling factor (assuming both slides have the same original dimensions)\n",
    "orig_width, _ = wsi_grayson.dimensions\n",
    "scale = thumb_grayson.width / orig_width\n",
    "\n",
    "# Define a simple color mapping\n",
    "color_map = {\n",
    "    'dysplasia': 'red',\n",
    "    'mild': 'orange',\n",
    "    'moderate': 'yellow',\n",
    "    'severe': 'purple'\n",
    "}\n",
    "\n",
    "def overlay_rois(ax, wsi_obj):\n",
    "    # Loop through each ROI and overlay a polygon\n",
    "    for roi in wsi_obj.rois:\n",
    "        poly_coords = np.array(roi.poly.exterior.coords) * scale\n",
    "        label = roi.label.lower() if roi.label else 'unknown'\n",
    "        #change any label that mentions a grade to dysplasia\n",
    "        if label in ['mild', 'moderate', 'severe']:\n",
    "            label = 'dysplasia'\n",
    "        color = color_map.get(label, 'green')\n",
    "        patch = MplPolygon(poly_coords, closed=True, edgecolor=color, fill=False, linewidth=2)\n",
    "        ax.add_patch(patch)\n",
    "        centroid = poly_coords.mean(axis=0)\n",
    "        ax.text(centroid[0], centroid[1], label, fontsize=8, color=color)\n",
    "\n",
    "# Create side-by-side plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# Grayson's overlay\n",
    "ax1.imshow(thumb_grayson)\n",
    "overlay_rois(ax1, wsi_grayson)\n",
    "ax1.set_title(\"Grayson's Annotations\")\n",
    "\n",
    "# Anna's overlay\n",
    "ax2.imshow(thumb_anna)\n",
    "overlay_rois(ax2, wsi_anna)\n",
    "ax2.set_title(\"Anna's Annotations\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative analysis of 24 slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary that maps slide name to path (since slides are stored in two different directories)\n",
    "import os\n",
    "\n",
    "slides_dir_1 = \"/home/joeychan/labshare/SLIDES/PDCD10/TAM_then_4NQO\"\n",
    "slides_dir_2 = \"/home/joeychan/labshare/SLIDES/PDCD10/4NQO_then_TAM\"\n",
    "\n",
    "# Collect all .svs files in both directories\n",
    "svs_map = {}\n",
    "\n",
    "for d in [slides_dir_1, slides_dir_2]:\n",
    "    #iterating through each file in the current directory (d is a string path but os.listdir returns a list of files in the directory)\n",
    "    for fname in os.listdir(d):\n",
    "        if fname.endswith(\".svs\"):\n",
    "            base_name = fname.replace(\".svs\", \"\")\n",
    "            svs_map[base_name] = os.path.join(d, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import slideflow as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon as MplPolygon\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "\n",
    "#directories for the annotation CSV files\n",
    "grayson_dir = \"/home/joeychan/labshare/PROJECTS/PDCD10/rois/grayson\"\n",
    "anna_dir = \"/home/joeychan/labshare/PROJECTS/PDCD10/rois/anna\"\n",
    "\n",
    "# Directory where comparison images will be saved\n",
    "output_dir = \"/home/joeychan/labshare/PROJECTS/PDCD10/roi_comparisons\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 3: Define a helper function to overlay ROIs on a given axis.\n",
    "# ---------------------------\n",
    "\n",
    "def overlay_rois(ax, wsi_obj, scale, color_map, area_threshold=0):\n",
    "\n",
    "    for roi in wsi_obj.rois:\n",
    "        # Determine if the ROI geometry is a Polygon or MultiPolygon\n",
    "        if roi.poly.geom_type == \"Polygon\":\n",
    "            polygons = [roi.poly]\n",
    "        elif roi.poly.geom_type == \"MultiPolygon\":\n",
    "            polygons = list(roi.poly.geoms)\n",
    "        else:\n",
    "            print(f\"Unknown geometry type: {roi.poly.geom_type} for ROI with label {roi.label}\")\n",
    "            continue\n",
    "        \n",
    "        # Use the same label for all sub-polygons\n",
    "        label = roi.label.lower() if roi.label else \"unknown\"\n",
    "        #change any label that mentions a grade to dysplasia\n",
    "        if label in ['mild', 'moderate', 'severe']:\n",
    "            label = 'dysplasia'\n",
    "        color = color_map.get(label, \"green\")\n",
    "        \n",
    "        for poly in polygons:\n",
    "            # Optionally filter out small polygons based on area\n",
    "            if poly.area < area_threshold:\n",
    "                continue\n",
    "            \n",
    "            # Scale the polygon coordinates to match the thumbnail dimensions.\n",
    "            poly_coords = np.array(poly.exterior.coords) * scale\n",
    "            \n",
    "            # Create and add the polygon patch to the axis.\n",
    "            patch = MplPolygon(poly_coords, closed=True, edgecolor=color, fill=False, linewidth=2)\n",
    "            ax.add_patch(patch)\n",
    "            \n",
    "            # Compute centroid for labeling.\n",
    "            # centroid = poly_coords.mean(axis=0)\n",
    "            # ax.text(centroid[0], centroid[1], label, fontsize=8, color=color)\n",
    "\n",
    "\n",
    "# Define a simple color mapping for different labels.\n",
    "color_map = {\n",
    "    \"dysplasia\": \"red\",\n",
    "    \"mild\": \"orange\",\n",
    "    \"moderate\": \"yellow\",\n",
    "    \"severe\": \"purple\",\n",
    "    \"benign\": \"blue\"\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 4: Loop over each CSV in Grayson's directory to build comparisons.\n",
    "# ---------------------------\n",
    "\n",
    "for csv_file in os.listdir(grayson_dir):\n",
    "    if csv_file.endswith(\".csv\"):\n",
    "        #print \"current csv file\"\n",
    "        print(\"current csv file: \", csv_file)\n",
    "        # Extract the base name (e.g., \"AF102F\" from \"AF102F.csv\")\n",
    "        base_name = csv_file.replace(\".csv\", \"\")\n",
    "        \n",
    "        # Look up the matching SVS file in the dictionary.\n",
    "        if base_name not in svs_map:\n",
    "            print(f\"No .svs file found for {base_name}, skipping.\")\n",
    "            continue\n",
    "        #Will use this path for both Grayson and Anna WSI objects \n",
    "        svs_path = svs_map[base_name]\n",
    "        \n",
    "        # Build full paths for the annotation CSV files for both pathologists.\n",
    "        grayson_csv = os.path.join(grayson_dir, csv_file)\n",
    "        anna_csv = os.path.join(anna_dir, csv_file)  # assuming the same filename\n",
    "        \n",
    "        # Check if Anna's CSV exists; if not, skip this slide.\n",
    "        if not os.path.exists(anna_csv):\n",
    "            print(f\"Anna's CSV for {base_name} not found, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Create WSI objects for Grayson and Anna using the same slide (svs_path)\n",
    "        wsi_grayson = sf.WSI(path=svs_path, tile_px=256, tile_um=128, rois=grayson_csv)\n",
    "        wsi_anna = sf.WSI(path=svs_path, tile_px=256, tile_um=128, rois=anna_csv)\n",
    "        \n",
    "        # Generate a thumbnail image without ROI overlays.\n",
    "        thumb_grayson = wsi_grayson.thumb(width=1024, rois=False)\n",
    "        thumb_anna = wsi_anna.thumb(width=1024, rois=False)\n",
    "        \n",
    "        # Calculate the scaling factor between original slide dimensions and thumbnail.\n",
    "        orig_width, _ = wsi_grayson.dimensions  # assume both have same dimensions\n",
    "        scale = thumb_grayson.width / orig_width\n",
    "        \n",
    "        # Create a side-by-side figure to compare the overlays.\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "        \n",
    "        # Display Grayson's thumbnail and overlay his ROIs.\n",
    "        ax1.imshow(thumb_grayson)\n",
    "        overlay_rois(ax1, wsi_grayson, scale, color_map)\n",
    "        ax1.set_title(f\"{base_name} - Grayson\")\n",
    "        \n",
    "        # Display Anna's thumbnail and overlay her ROIs.\n",
    "        ax2.imshow(thumb_anna)\n",
    "        overlay_rois(ax2, wsi_anna, scale, color_map)\n",
    "        ax2.set_title(f\"{base_name} - Anna\")\n",
    "        \n",
    "        # Save the comparison figure.\n",
    "        outpath = os.path.join(output_dir, f\"{base_name}_comparison.png\")\n",
    "        plt.savefig(outpath, dpi=150)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        print(f\"Saved comparison image for {base_name} to {outpath}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Define the output directory where the PNGs are stored.\n",
    "output_dir = \"/home/joeychan/labshare/PROJECTS/PDCD10/roi_comparisons\"\n",
    "\n",
    "# Get a sorted list of all PNG files in the directory.\n",
    "png_files = sorted([f for f in os.listdir(output_dir) if f.endswith(\".png\")])\n",
    "\n",
    "# Loop over the files and display each one individually.\n",
    "for png_file in png_files:\n",
    "    file_path = os.path.join(output_dir, png_file)\n",
    "    print(png_file)  # Optionally print the file name.\n",
    "    display(Image(filename=file_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data for Centerline Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternative method for loading the data\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = \"/home/joeychan/labshare/PROJECTS/PDCD10/rois/anna/AF110F.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Group points by ROI name\n",
    "roi_polygons = {}\n",
    "#note that groupby is grouping by the roi_name column\n",
    "#note that group is just a subset of the dataframe corresponding to the roi_name\n",
    "for roi_name, group in df.groupby(\"roi_name\"):\n",
    "    #taking the two series of x and y coordinates and zipping them together. Zip needs two interables and makes tuples\n",
    "    points = list(zip(group[\"x_base\"], group[\"y_base\"]))  # Convert to (x, y) coordinates\n",
    "    #adding to the dictionary\n",
    "    roi_polygons[roi_name] = Polygon(points)  # Create Shapely Polygon\n",
    "\n",
    "#pritning dictionary here\n",
    "for roi, poly in roi_polygons.items():\n",
    "    print(f\"ROI {roi}: Area = {poly.area}, Length = {poly.length}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Voroni Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon, LineString, MultiLineString, Point\n",
    "from shapely.ops import unary_union\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "\n",
    "# Select an example ROI polygon\n",
    "roi_polygon = roi_polygons[\"ROI_2\"]  # Replace with different ROI if needed\n",
    "\n",
    "# Extract boundary points from the polygon\n",
    "boundary_coords = np.array(roi_polygon.exterior.coords)\n",
    "\n",
    "# Compute Voronoi diagram from boundary points\n",
    "vor = Voronoi(boundary_coords)\n",
    "fig = voronoi_plot_2d(vor)\n",
    "plt.title(\"Voronoi Graph\")\n",
    "plt.show()\n",
    "\n",
    "#get the vertices that define the regions\n",
    "vor_vertices = vor.vertices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph based with additional changes\n",
    "\n",
    "Tried percetile based trimming and it works really well! Before ends of the graph based method were not representative of the centerline. Trimming seems to be a simpler solution rather than filtering based on width, angle, etc. 10% seems to be a good threshold. \n",
    "\n",
    "Note: can take a while because after finding terminal nodes, we are using a doule for loop. Must be a way to optimize this since there is some redudancy. IF you iterate through a terminal node and its distance to all other terminal nodes, you are going to repreat some measurements when you run on another node..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon, LineString, MultiLineString, Point\n",
    "from shapely.ops import unary_union\n",
    "from scipy.spatial import Voronoi\n",
    "\n",
    "# --------------------------\n",
    "# 1) Percentile-based Trim\n",
    "# --------------------------\n",
    "def trim_ends_by_percentile(centerline, polygon, low_pct=10):\n",
    "    \"\"\"\n",
    "    Trims centerline points whose distance to polygon boundary\n",
    "    is below the `low_pct` percentile of all distances.\n",
    "    This automatically adapts to different ROI shapes & sizes.\n",
    "    \"\"\"\n",
    "    if not centerline or not len(centerline.coords):\n",
    "        return None\n",
    "\n",
    "    coords = list(centerline.coords)\n",
    "\n",
    "    # 1. Compute distance to boundary for all points\n",
    "    #same size as the coords list and first entry here corresponds to the distance of the first point in coords to the boundary, etc. \n",
    "    #This allows us to zip the two lists together and then filter based on the distance later on\n",
    "    dists = [polygon.exterior.distance(Point(pt)) for pt in coords]\n",
    "\n",
    "    # 2. Determine cutoff using low percentile\n",
    "    # so if it's 10 it means cutoff is 10th percentile of distances \n",
    "    # (idea is that the points with the smallest distances to boundary are the \"tails\" we noticed that aren't part of the true centerline )\n",
    "    cutoff = np.percentile(dists, low_pct)\n",
    "\n",
    "    # 3. Keep only points with distance >= cutoff\n",
    "    new_coords = [pt for pt, dist in zip(coords, dists) if dist >= cutoff]\n",
    "\n",
    "    # 4. Rebuild centerline\n",
    "    if len(new_coords) < 2:\n",
    "        return None\n",
    "    return LineString(new_coords)\n",
    "\n",
    "# --------------------------\n",
    "# 2) Your Existing Voronoi + Graph Steps\n",
    "# --------------------------\n",
    "\n",
    "# For example, choose an ROI to process\n",
    "roi_name = \"ROI_2\"\n",
    "roi_polygon = roi_polygons[roi_name]\n",
    "\n",
    "# Extract boundary points\n",
    "boundary_coords = np.array(roi_polygon.exterior.coords)\n",
    "\n",
    "# Compute Voronoi\n",
    "vor = Voronoi(boundary_coords)\n",
    "\n",
    "# Filter Voronoi edges inside the polygon\n",
    "valid_lines = []\n",
    "for vpair in vor.ridge_vertices:\n",
    "    if -1 in vpair:  \n",
    "        continue\n",
    "    p1, p2 = vor.vertices[vpair[0]], vor.vertices[vpair[1]]\n",
    "    line = LineString([p1, p2])\n",
    "    if roi_polygon.contains(line):\n",
    "        valid_lines.append(line)\n",
    "\n",
    "# Merge edges into a single geometry\n",
    "medial_axis = unary_union(valid_lines)\n",
    "\n",
    "# Convert to graph\n",
    "def medial_axis_to_graph(medial_axis):\n",
    "    G = nx.Graph()\n",
    "    if isinstance(medial_axis, MultiLineString):\n",
    "        for line in medial_axis.geoms:\n",
    "            coords = list(line.coords)\n",
    "            for i in range(len(coords) - 1):\n",
    "                #the weight is the distance between the two points\n",
    "                seg_length = Point(coords[i]).distance(Point(coords[i+1]))\n",
    "                G.add_edge(coords[i], coords[i+1], weight=seg_length)\n",
    "    elif isinstance(medial_axis, LineString):\n",
    "        coords = list(medial_axis.coords)\n",
    "        for i in range(len(coords) - 1):\n",
    "            seg_length = Point(coords[i]).distance(Point(coords[i+1]))\n",
    "            G.add_edge(coords[i], coords[i+1], weight=seg_length)\n",
    "    return G\n",
    "\n",
    "G = medial_axis_to_graph(medial_axis)\n",
    "\n",
    "# Largest connected component\n",
    "largest_cc = max(nx.connected_components(G), key=len)\n",
    "G_largest = G.subgraph(largest_cc).copy()\n",
    "\n",
    "# Find the longest path among terminal nodes\n",
    "def find_longest_path(G_largest):\n",
    "    #iterating through all nodes and keeping the ones with degree 1 (terminal nodes)\n",
    "    print(\"finding terminal nodes\")\n",
    "    terminal_nodes = [n for n in G_largest.nodes if G_largest.degree[n] == 1]\n",
    "    #print number of terminal nodes\n",
    "    print(f\"number of terminal nodes: {len(terminal_nodes)}\")\n",
    "    if len(terminal_nodes) < 2:\n",
    "        return None\n",
    "\n",
    "    max_length = 0\n",
    "    best_pair = None\n",
    "    #double loop tof find distance between each pair of terminal nodes\n",
    "    #two terminal nodes that are furthest apart should represent the centerline\n",
    "    print(\"finding longest path\")\n",
    "    for i in range(len(terminal_nodes)):\n",
    "        for j in range(i+1, len(terminal_nodes)):\n",
    "            try:\n",
    "                path_length = nx.shortest_path_length(\n",
    "                    G_largest, terminal_nodes[i], terminal_nodes[j], weight=\"weight\"\n",
    "                )\n",
    "                if path_length > max_length:\n",
    "                    max_length = path_length\n",
    "                    #update best pair to this one with the longest distance\n",
    "                    best_pair = (terminal_nodes[i], terminal_nodes[j])\n",
    "            except nx.NetworkXNoPath:\n",
    "                pass\n",
    "\n",
    "    if not best_pair:\n",
    "        return None\n",
    "    #returns the longest path between the two terminal nodes\n",
    "    return nx.shortest_path(G_largest, source=best_pair[0], target=best_pair[1], weight=\"weight\")\n",
    "\n",
    "longest_path = find_longest_path(G_largest)\n",
    "if longest_path:\n",
    "    centerline = LineString(longest_path)\n",
    "else:\n",
    "    centerline = None\n",
    "\n",
    "# --------------------------\n",
    "# 3) Apply Percentile-based Trim\n",
    "# --------------------------\n",
    "#centerline is longest path but may have tails--->trim the line to get the true centerline\n",
    "if centerline:\n",
    "    # e.g., low_pct=10 means removing points in the lower 10% boundary distance\n",
    "    centerline = trim_ends_by_percentile(centerline, roi_polygon, low_pct=10)\n",
    "\n",
    "# --------------------------\n",
    "# 4) Visualization\n",
    "# --------------------------\n",
    "if centerline and len(centerline.coords) > 1:\n",
    "    print(f\"[{roi_name}] Centerline Length (after percentile trim):\", centerline.length)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "x, y = roi_polygon.exterior.xy\n",
    "ax.plot(x, y, linestyle=\"-\", color=\"blue\", label=\"ROI Boundary\")\n",
    "\n",
    "if centerline and len(centerline.coords) > 1:\n",
    "    cx, cy = centerline.xy\n",
    "    ax.plot(cx, cy, linestyle=\"--\", color=\"red\", linewidth=2, label=\"Refined Centerline\")\n",
    "\n",
    "plt.xlabel(\"X-coordinates\")\n",
    "plt.ylabel(\"Y-coordinates\")\n",
    "plt.title(f\"Final Centerline with Percentile-based Trimming ({roi_name})\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
